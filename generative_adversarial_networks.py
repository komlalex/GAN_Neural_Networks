import torch 
import torch.nn as nn 
import torch.nn.functional as F
from torch.utils.data import DataLoader 


from torchvision.datasets import ImageFolder 
from torchvision.utils import make_grid, save_image
import torchvision.transforms as T 

import matplotlib.pyplot as plt

from pathlib import Path

"""Generative Adverserial Networks: a Generator and a Discriminator. 
The generator generates a "fake" sample given a random vector/matrix, and the 
discriminator attempts to detect whether a given sample is "real" (picked from the training data) or "fake"
(generated by the generator). Training happens in tandem: we train the discriminator for 
a few epochs, then train the generator for a few epochs, and repeat. This way
both the generator and the discriminator get better after doing their jobs. 
We'll use the Anime Face Dataset, which consists of over 63,000 cropped anime faces. Not
that generative modelling is an unsupervised learning task, so the images do 
not have any labels.""" 


"""Let's load this dataset using the ImageFolder class from torchvision. We will also
resize and crop the images to 64x64, normalize the pixel values with a mean & standard deviation of 0.5 for 
each channel. This will ensure that pixel values are in the range(-1, 1), which is more convenenient for 
training the discriminator. We will also create a data loader to load the data in batches"""
TRAIN_DIR = Path("data")
IMAGE_SIZE = 64 
BATCH_SIZE = 128 
STATS = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)

train_ds = ImageFolder(TRAIN_DIR, transform=T.Compose([
    T.Resize(IMAGE_SIZE),
    T.CenterCrop(IMAGE_SIZE),
    T.ToTensor(), 
    T.Normalize(*STATS)
])) 

train_dl = DataLoader(train_ds, 
                    shuffle=True,
                    batch_size=BATCH_SIZE, 
                    pin_memory=True) 

def denorm(img_tensors):
    return img_tensors * STATS[1][0] + STATS[0][0]  

def show_images(images, nmax=64):
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([]) 
    ax.imshow(make_grid( denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))

def show_batch(dl, nmax=64): 
    for images, _ in dl:
        show_images(images, nmax)
        break 

show_batch(train_dl)


""""Using a GPU
To seamlessly use a GPU, if one is available, we define a couple of helper functions (get_default_device & to_device) 
and a helper class DeviceDataLoader to move our model & data to the GPU, if one is available.
"""


def get_default_device(): 
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device("cuda") 
    else: 
        return torch.device("cpu") 


def to_device(data, device):
    """Move tensor(s) to chosen device""" 
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data] 
    
    return data.to(device, non_blocking=True) 

class DeviceDataLoader():
    """Wrap a dataloader to move data to device"""
    def __init__(self, dl, device):
        self.dl = dl 
        self.device = device 
    
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)  

    def __len__(self): 
        """Number of batches"""
        return len(self.dl) 

device = get_default_device() 

train_dl = DeviceDataLoader(train_dl, device)

"""The Discriminator
The discriminator takes an image as an input, and tries to classify it as "real" or "generated". 
In this sense, it's any other neural network. We'll use a convolutional neural network (CNN) which outputs 
a single number for every image. We'll use stride 2 to progressively reduce the size of the output feature 
map""" 

discriminator = nn.Sequential(
    # in: 3 x 64 x 64 
    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(64), 
    nn.LeakyReLU(0.2, inplace=True), 
    # out: 64 x 32 x 32 

    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(256), 
    nn.LeakyReLU(0.2 ,inplace=True),
    # out: 128 x 16 x 16

    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(256), 
    nn.LeakyReLU(0.2, inplace=True),
    # out: 256 x 8 x 8 

    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(512), 
    nn.LeakyReLU(0.2, inplace=True),
    # out: 512 x 4 x 4  

    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),
    # out: 1 x 1 x 1

    nn.Flatten(), 
    nn.Sigmoid()
)

"""The LeakyReLU 
is different from the regular ReLU as it allows the pass of a 
small gradient for negative values. As a result, it makes the gradient from the 
discriminator flow stronger in the generator. Instead of passing a gradient (slope)
of 0 in the back-drop, it passes a small negative gradient.""" 

"""Just like any other binary classification model, the output of the discriminator is a
single number between 0 and 1, which can be interpreted as the probability of the input 
being real i.e. picked from the origininal dataset""" 

discriminator = to_device(discriminator, device) 

"""Generator Network
The input to the generator network is typically a vector or matrix of random numbers 
(referred to as a latent tensor) which is used as a seed for generating an image. 
The generator will convert a latent tenstor of shape (128, 1, 1) into an image tensor of shape 3x28x28. To 
achieve this, we'll use the ConTranspose2d layer from PyTorch, which performs a transposed convolution.
"""
latent_size = 128 

generator = nn.Sequential(
    # in: latent_size x 1 x 1 

    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False), 
    nn.BatchNorm2d(512), 
    nn.ReLU(True), 
    # out: 512 x 4 x 4  

    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(256), 
    nn.ReLU(True), 
    # out: 128 x 16 x 16 

    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(128), 
    nn.ReLU(True),  
    # out: 128 x 16 x 16 

    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(64), 
    nn.ReLU(True), 
    # out: 64 x 32 x 32 

    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.Tanh()
    # out: 3 x 64 x 64 
)

"""We use the TanH activation function for the output layer of the generator. 

"The ReLU activation (Nair & Hinton, 2010) is used in the generator with the exception 
of the output layer which uses the Tanh function. We observed that using a bounded activation allowed 
the model to learn more quickly to saturate and cover the color space of the training distribution. 
Within the discriminator we found the leaky rectified activation (Maas et al, 2013) 
(Xu et al. 2015) worked well, especially for higher resolution modelling"
"""

"""Note that since the outputs of the TanH activation lie in the range [-1, 1], we have applied 
the similar transformation to the images in the training dataset. Let's generate some outputs 
using the generator and and view them as images by transforming and denormaliziing
"""

xb = torch.randn(BATCH_SIZE, latent_size, 1, 1) # random latent tensors 

fake_images = generator(xb) 
print(xb.shape)
print(fake_images.shape) 
show_images(fake_images)


""""As one might expect, the output from the generator is basically random noise, 
since we haven't trained it yet. 

Let's now move the generator to the chosen device.""" 
generator = to_device(generator, device) 

"""Discriminator Training 
Since the discriminator is a binary classification model, 
we can use the binary cross entropy loss function to quantify how well it is able 
to differentiate between reala and generated images.""" 

def train_discriminator(real_images: torch.Tensor, opt_d: torch.optim.Optimizer): 
     # Clear discriminator gradients 
     opt_d.zero_grad()

     # Pass the real images through the discriminator 
     real_preds = discriminator(real_images) 
     real_targets = torch.ones(real_images.size(0), 1, device=device) 
     real_loss = F.binary_cross_entropy(real_preds, real_targets)  
     real_score = torch.mean(real_preds).item()

     # Generate fake images 
     latent = torch.randn(BATCH_SIZE, latent_size, 1 , 1, device=device)
     fake_images = generator(latent) 

     # Pass fake images through discriminator 
     fake_targets = torch.zeros(fake_images.size(0), 1 , device=device)
     fake_preds = discriminator(fake_images) 
     fake_loss = F.binary_cross_entropy(fake_preds, fake_targets) 
     fake_score = torch.mean(fake_preds).item() 

     # Update disciminator
     loss = real_loss + fake_loss 
     loss.backward()  
     opt_d.step() 
     return loss.item(), real_score, fake_score

"""Here are the steps involved in training the discriminator.
* We expect the discriminator to ouput 1 if the images are picked from the real MNIST dataset, 
and 0 if it is generated using the generator network.
* We first pass a batch of real images, and compute the loss, setting the target labels to 1. 
* We then pass a batch of fake images (generated using the generator) pass them into the discriminator 
and compute the loss, settting the target to 0. 
* Finally we add the two losses and use the overall loss to perform gradient descent to adjust the weights. 
"""

"""Generator Training 
Since the outputs of the generator are images, it's obvious how to train the generator. 
This is where we employ the rather elegant trick, which is to use the discriminator as a 
part of the loss function. Here's how it works: 
* We generate a batch of images using the generator, pass the input into the discriminator.
* We calculate the loss by setting the target labels to 1 i.e real. We do this because 
the genrator's objective is to "fool" the discriminator. 
* We use the loss to perform gradient descent i.e change the weights of the generator, so it 
gets better at generating real-like images to "fool" the discriminator.

Here's what this looks like""" 

def train_generator(opt_g:torch.optim.Optimizer):  
    # Clear the generator gradients 
    opt_g.zero_grad() 

    # Generator fake images 
    latent = torch.randn(BATCH_SIZE, latent_size, 1, 1, device=device) 
    fake_images = generator(latent) 

    # Try to fool the discriminator 
    preds = discriminator(fake_images)
    targets = torch.ones(BATCH_SIZE, 1, device=device) 
    loss = F.binary_cross_entropy(preds, targets) 

    # Update generator weights 
    loss.backward() 
    opt_g.step()  


    return loss.item()

"""Let's create a directory where we can save intermediate outputs from the 
generator to visually inspect the progress of the model. We'll also create a helper function to export 
generated images."""  
gen_dir = Path("generated/") 
gen_dir.mkdir(parents=True, exist_ok=True) 

def save_samples(index, latent_tensors, show=True): 
    fake_images = generator(latent_tensors)
    fake_fname = f"generated-images{index:0=4d}.png"  
    fake_fpath = gen_dir/fake_fname
    save_image(denorm(fake_images), fake_fpath ) 
    print("Saving")
    if show:
        fig, ax = plt.subplots(figsize=(8, 8)) 
        ax.set_xticks([]); ax.set_yticks([]) 
        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0)) 

"""We use a fixed set of input vectors to the generator to see how the individual 
generted images evolve over time as we train the model. Let's save one set of images before we 
start training our model.
"""
fixed_latent = torch.randn(64, latent_size, 1, 1, device= device) 
save_samples(1,fixed_latent )  
plt.show()
"""Full Training """