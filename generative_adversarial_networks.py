import torch 
import torch.nn as nn 
import torch.nn.functional as F
from torch.utils.data import DataLoader 


from torchvision.datasets import ImageFolder 
from torchvision.utils import make_grid 
import torchvision.transforms as T 

import matplotlib.pyplot as plt

from pathlib import Path

"""Generative Adverserial Networks: a Generator and a Discriminator. 
The generator generates a "fake" sample given a random vector/matrix, and the 
discriminator attempts to detect whether a given sample is "real" (picked from the training data) or "fake"
(generated by the generator). Training happens in tandem: we train the discriminator for 
a few epochs, then train the generator for a few epochs, and repeat. This way
both the generator and the discriminator get better after doing their jobs. 
We'll use the Anime Face Dataset, which consists of over 63,000 cropped anime faces. Not
that generative modelling is an unsupervised learning task, so the images do 
not have any labels."""
TRAIN_DIR = Path("data")
IMAGE_SIZE = 64 
BATCH_SIZE = 128 
STATS = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)

train_ds = ImageFolder(TRAIN_DIR, transform=T.Compose([
    T.Resize(IMAGE_SIZE),
    T.CenterCrop(IMAGE_SIZE),
    T.ToTensor(), 
    T.Normalize(*STATS)
])) 

train_dl = DataLoader(train_ds, 
                    shuffle=True,
                    batch_size=BATCH_SIZE, 
                    pin_memory=True) 

def denorm(img_tensors):
    return img_tensors * STATS[1][0] + STATS[0][0]  

def show_images(images, nmax=64):
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([]) 
    ax.imshow(make_grid( denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))
    plt.title("Sample Batch")

def show_batch(dl, nmax=64): 
    for images, _ in dl:
        print(images.shape)
        show_images(images, nmax)
        break 

show_batch(train_dl)



def get_default_device(): 
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device("cuda") 
    else: 
        return torch.device("cpu") 


def to_device(data, device):
    """Move tensor(s) to chosen device""" 
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data] 
    
    return data.to(device, non_blocking=True) 

class DeviceDataLoader():
    """Wrap a dataloader to move data to device"""
    def __init__(self, dl, device):
        self.dl = dl 
        self.device = device 
    
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)  

    def __len__(self): 
        """Number of batches"""
        return len(self.dl) 

device = get_default_device() 
print(device)

plt.show()





