import torch 
import torch.nn as nn 
import torch.nn.functional as F
from torch.utils.data import DataLoader 


from torchvision.datasets import ImageFolder 
from torchvision.utils import make_grid 
import torchvision.transforms as T 

import matplotlib.pyplot as plt

from pathlib import Path

"""Generative Adverserial Networks: a Generator and a Discriminator. 
The generator generates a "fake" sample given a random vector/matrix, and the 
discriminator attempts to detect whether a given sample is "real" (picked from the training data) or "fake"
(generated by the generator). Training happens in tandem: we train the discriminator for 
a few epochs, then train the generator for a few epochs, and repeat. This way
both the generator and the discriminator get better after doing their jobs. 
We'll use the Anime Face Dataset, which consists of over 63,000 cropped anime faces. Not
that generative modelling is an unsupervised learning task, so the images do 
not have any labels.""" 


"""Let's load this dataset using the ImageFolder class from torchvision. We will also
resize and crop the images to 64x64, normalize the pixel values with a mean & standard deviation of 0.5 for 
each channel. This will ensure that pixel values are in the range(-1, 1), which is more convenenient for 
training the discriminator. We will also create a data loader to load the data in batches"""
TRAIN_DIR = Path("data")
IMAGE_SIZE = 64 
BATCH_SIZE = 128 
STATS = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)

train_ds = ImageFolder(TRAIN_DIR, transform=T.Compose([
    T.Resize(IMAGE_SIZE),
    T.CenterCrop(IMAGE_SIZE),
    T.ToTensor(), 
    T.Normalize(*STATS)
])) 

train_dl = DataLoader(train_ds, 
                    shuffle=True,
                    batch_size=BATCH_SIZE, 
                    pin_memory=True) 

def denorm(img_tensors):
    return img_tensors * STATS[1][0] + STATS[0][0]  

def show_images(images, nmax=64):
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([]) 
    ax.imshow(make_grid( denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))

def show_batch(dl, nmax=64): 
    for images, _ in dl:
        show_images(images, nmax)
        break 

show_batch(train_dl)


""""Using a GPU
To seamlessly use a GPU, if one is available, we define a couple of helper functions (get_default_device & to_device) 
and a helper class DeviceDataLoader to move our model & data to the GPU, if one is available.
"""


def get_default_device(): 
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device("cuda") 
    else: 
        return torch.device("cpu") 


def to_device(data, device):
    """Move tensor(s) to chosen device""" 
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data] 
    
    return data.to(device, non_blocking=True) 

class DeviceDataLoader():
    """Wrap a dataloader to move data to device"""
    def __init__(self, dl, device):
        self.dl = dl 
        self.device = device 
    
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)  

    def __len__(self): 
        """Number of batches"""
        return len(self.dl) 

device = get_default_device() 

train_dl = DeviceDataLoader(train_dl, device)

"""The Discriminator
The discriminator takes an image as an input, and tries to classify it as "real" or "generated". 
In this sense, it's any other neural network. We'll use a convolutional neural network (CNN) which outputs 
a single number for every image. We'll use stride 2 to progressively reduce the size of the output feature 
map""" 

discriminator = nn.Sequential(
    # in: 3 x 64 x 64 
    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(64), 
    nn.LeakyReLU(0.2, inplace=True), 
    # out: 64 x 32 x 32 

    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(256), 
    nn.LeakyReLU(0.2 ,inplace=True),
    # out: 128 x 16 x 16

    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(256), 
    nn.LeakyReLU(0.2, inplace=True),
    # out: 256 x 8 x 8 

    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(512), 
    nn.LeakyReLU(0.2, inplace=True),
    # out: 512 x 4 x 4  

    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),
    # out: 1 x 1 x 1

    nn.Flatten(), 
    nn.Sigmoid()
)

"""The LeakyReLU 
is different from the regular ReLU as it allows the pass of a 
small gradient for negative values. As a result, it makes the gradient from the 
discriminator flow stronger in the generator. Instead of passing a gradient (slope)
of 0 in the back-drop, it passes a small negative gradient.""" 

"""Just like any other binary classification model, the output of the discriminator is a
single number between 0 and 1, which can be interpreted as the probability of the input 
being real i.e. picked from the origininal dataset""" 

discriminator = to_device(discriminator, device) 

"""Generator Network
The input to the generator network is typically a vector or matrix of random numbers 
(referred to as a latent tensor) which is used as a seed for generating an image. 
The generator will convert a latent tenstor of shape (128, 1, 1) into an image tensor of shape 3x28x28. To 
achieve this, we'll use the ConTranspose2d layer from PyTorch, which performs a transposed convolution.
"""
latent_size = 128 

generator = nn.Sequential(
    # in: latent_size x 1 x 1 

    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False), 
    nn.BatchNorm2d(512), 
    nn.ReLU(True), 
    # out: 512 x 4 x 4  

    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(256), 
    nn.ReLU(True), 
    # out: 128 x 16 x 16 

    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(128), 
    nn.ReLU(True),  
    # out: 128 x 16 x 16 

    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.BatchNorm2d(64), 
    nn.ReLU(True), 
    # out: 64 x 32 x 32 

    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False), 
    nn.Tanh()
    # out: 3 x 64 x 64 
)

"""We use the TanH activation function for the output layer of the generator. 

"The ReLU activation (Nair & Hinton, 2010) is used in the generator with the exception 
of the output layer which uses the Tanh function. We observed that using a bounded activation allowed 
the model to learn more quickly to saturate and cover the color space of the training distribution. 
Within the discriminator we found the leaky rectified activation (Maas et al, 2013) 
(Xu et al. 2015) worked well, especially for higher resolution modelling"
"""

"""Note that since the outputs of the TanH activation lie in the range [-1, 1], we have applied 
the similar transformation to the images in the training dataset. Let's generate some outputs 
using the generator and and view them as images by transforming and denormaliziing
"""

xb = torch.randn(BATCH_SIZE, latent_size, 1, 1) # random latent tensors 

fake_images = generator(xb) 
print(xb.shape)
print(fake_images.shape) 
show_images(fake_images)
plt.show() 